{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a href=#>\n",
    "    <img src=\"https://i.imgur.com/Uid1O3A.png\" alt=\"Dicom Viewer\" width=\"96\" height=\"96\">\n",
    "  </a>\n",
    "  <h2 align=\"center\">語音數字辨識專案 (Spoken-Digit Recognizer)</h2>\n",
    "  <br>\n",
    "</p>\n",
    "\n",
    "\n",
    "<div align=\"center\">\n",
    "    本project旨在運用Keras建立Model，辨識使用者說的中/英數字，並使用GUI呈現。\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Split--Audio-src-brightgreen.svg)](#) | [![](https://img.shields.io/badge/Spectrogram%2BCNN-src-brightgreen.svg)](#) | [![](https://img.shields.io/badge/MFCC%2BRNN-src-brightgreen.svg)](#) | [![](https://img.shields.io/badge/GAN-src-brightgreen.svg)](#) | [![](https://img.shields.io/badge/Demo-src-brightgreen.svg)](#)\n",
    "- | - | - | - | -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![](https://img.shields.io/badge/Split--Audio-doc-blue.svg)](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/split_audio.ipynb) | [![](https://img.shields.io/badge/Spectrogram%2BCNN-doc-blue.svg)](#) | [![](https://img.shields.io/badge/MFCC%2BRNN-doc-blue.svg)](#) | [![](https://img.shields.io/badge/GAN-doc-blue.svg)](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/GAN_doc.ipynb) | [![](https://img.shields.io/badge/Demo-doc-blue.svg)](https://nbviewer.jupyter.org/github/wenya-chungyuan-jauhhsiang/Spoken-Digit-Recognizer/blob/master/docs/Demo_doc.ipynb)\n",
    "- | - | - | - | -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先看段Demo吧\n",
    "### [Demo影片 (Spoken-Digit Recognizer)](#)\n",
    "這邊應該要是個GIF，先用照片擋著用\n",
    "<a href=#>\n",
    "    <img src=\"resources/demo.png\" alt=\"demo\" width=\"480\" height=\"480\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset（英文）\n",
    "- [pannous on github](https://github.com/pannous/tensorflow-speech-recognition?fbclid=IwAR1tThhKhbMM_BnKE4SK16qcbuGdw1gJw7iWVVyEhDk9vZFF5Z8E6rjuWUs)\n",
    "    - 連結內spoken_numbers_pcm.tar含2400筆.wav檔，為15位不同人唸英文數字0~9的單數字音檔（160/人）。\n",
    "- 3位contributer每人自錄160筆，與上述相加共2880筆\n",
    "\n",
    "## Dataset（中文）\n",
    "- 3位contributer每人自錄500筆，共1500筆\n",
    "    - 每筆data為中文數字數字0~9單數字音檔，每人一個數字錄50筆"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標\n",
    "1. 使用者對麥克風説一串中/英文數字(0~9)，程式能辨識使用者說了哪些數字  \n",
    "2. 使用生成對抗網路GAN來生成音檔，即讓程式產出數字0~9的音檔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "對目標1.，先將包含多數字的音檔分割，再使用不同種model來辨識，詳細介紹請點連結\n",
    "- ### [Split_Audio](#)\n",
    "- ### [Spectrogram + CNN](#)    \n",
    "- ### [MFCC + RNN](#)\n",
    "\n",
    "對目標2.，使用inverse-STFT方式，詳細介紹請點連結\n",
    "- ### [GAN](#)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問題討論\n",
    "### 1. 聲紋影響\n",
    "    - 一個沒有經過我們model訓練過的人聲，若進行辨識測驗時的平均正確率會較低\n",
    "    - 我們認為這和聲紋息息相關，也就是同樣的字由不同人發聲的訊號頻譜存在差異\n",
    "### 2. 中/英文\n",
    "    - 我們初期是以英文數字為輸入音訊，後期則發現英文其實在發音上相較中文有更多的變化性，如某些子音的發音屬於清音，會較容易被誤判為靜音\n",
    "    - 英文對於發音並沒有制式的音調規則，例如有些字會因語氣不同而音調不同，這導致我們model的辨識正確率並不理想\n",
    "    - 後來我們選擇嘗試中文，由於中文絕大多數發音是濁音，且抑揚頓挫已有明確定義，因此訓練出的model辨識正確率果然如我們預期，有明顯的提升"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributer\n",
    "[WenYa Lin](https://github.com/wenyalintw)、[ChungYuan Hsu](https://github.com/ChungYuanHsu)、[JauhHsiang Lan](https://github.com/r07522749)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
